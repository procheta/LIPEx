{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python3\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n",
    "from datasets import load_dataset\n",
    "from statistics import mode\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('GPU:',torch.cuda.get_device_name(device=device))\n",
    "\n",
    "label_names =[\"hate speech\", \"normal\", \"offensive\"]\n",
    "    \n",
    "# Loading data\n",
    "dataset = load_dataset('hatexplain', split='test')\n",
    "processed_data = []\n",
    "for id, ann, rationale, post in zip(dataset['id'], dataset['annotators'], dataset['rationales'], dataset['post_tokens']):\n",
    "    if rationale != []:\n",
    "        if len(rationale) == 2:\n",
    "            token_label = [1 if i > 1 else 0 for i in [rationale[0][j]+rationale[1][j] for j in range(len(rationale[0]))]]\n",
    "        elif len(rationale) == 3:\n",
    "            token_label = [1 if i > 1 else 0 for i in [rationale[0][j]+rationale[1][j]+rationale[2][j] for j in range(len(rationale[0]))]]\n",
    "        else:\n",
    "            raise ValueError(\"Rationale length is not 2 or 3\")\n",
    "        \n",
    "        label = ann['label']\n",
    "        gold_label = mode(label)\n",
    "\n",
    "            \n",
    "        processed_data.append({'id': id, 'label': gold_label, 'token_label': token_label, 'post': post})\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "print(f\"Number of processed data: {len(processed_data)}\")\n",
    "print(f\"Example of processed data: {processed_data[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_LM = \"Hate-speech-CNERG/bert-base-uncased-hatexplain\"\n",
    "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_LM)\n",
    "model = BertForSequenceClassification.from_pretrained(PRETRAINED_LM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(docs):\n",
    "    encoded_dict = tokenizer(docs, add_special_tokens=True, padding=True, return_attention_mask=True, truncation=True, return_tensors='pt') # max_length to be defined\n",
    "    input_ids = encoded_dict['input_ids']\n",
    "    attention_masks = encoded_dict['attention_mask']\n",
    "    return input_ids, attention_masks\n",
    "\n",
    "# Wrap tokenizer and model for LIME\n",
    "class pipeline(object):\n",
    "    def __init__(self, model, encoder): \n",
    "        self.model = model.to(device)\n",
    "        self.encoder = encoder\n",
    "        self.model.eval()\n",
    "    \n",
    "    def predict(self, text, batch_size=64): #batch_size to be defined\n",
    "        num_batches = int(len(text)/batch_size) if len(text)%batch_size == 0 else int(len(text)/batch_size)+1\n",
    "        out = []\n",
    "        for num in range(num_batches):\n",
    "            batch_text = text[num*batch_size:(num+1)*batch_size]\n",
    "\n",
    "            batch_input_ids,batch_attention_mask = self.encoder(batch_text)\n",
    "\n",
    "            batch_input_ids = batch_input_ids.to(device)\n",
    "            batch_attention_mask = batch_attention_mask.to(device)\n",
    "\n",
    "            batch_output = self.model(input_ids=batch_input_ids, attention_mask=batch_attention_mask).logits # (batch_size, num_class)\n",
    "            batch_out = batch_output.softmax(dim=-1).cpu().detach().tolist() # (batch_size, num_class)\n",
    "            out += batch_out\n",
    "        return np.array(out)\n",
    "\n",
    "c = pipeline(model,encoder=encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnt = 0\n",
    "# for idx in range(len(processed_data)):\n",
    "\n",
    "#     post_tokens = processed_data[idx]['post']\n",
    "#     text = \" \".join(post_tokens)\n",
    "#     label = processed_data[idx]['label']\n",
    "\n",
    "#     output = c.predict([text]) # (num_text, num_class)\n",
    "#     _, predicted = torch.max(torch.tensor(output), 1)\n",
    "#     pred_label= predicted.detach().numpy()[0] #  Predicted top label index\n",
    "#     print('label:',label,'pred_label:',pred_label)\n",
    "\n",
    "#     if pred_label == label:\n",
    "#         cnt += 1\n",
    "\n",
    "# print(f\"Accuracy: {cnt/len(processed_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append('../')\n",
    "from lime_new.lime_text import LimeTextExplainer\n",
    "\n",
    "union_num = 5 # to be defined\n",
    "num_samples = 1000\n",
    "\n",
    "def split_expression(text):\n",
    "    return text.split(' ')\n",
    "\n",
    "LIPEx_recall_values, LIPEx_precision_values, LIPEx_f1_values = [], [], []\n",
    "LIME_recall_values, LIME_precision_values, LIME_f1_values = [], [], []\n",
    "for idx in range(len(processed_data))[:100]:\n",
    "\n",
    "    post_tokens = processed_data[idx]['post']\n",
    "    token_labels = processed_data[idx]['token_label']\n",
    "    gold_tokens = [post_tokens[i] for i in range(len(post_tokens)) if token_labels[i] == 1]\n",
    "    text = \" \".join(post_tokens)\n",
    "\n",
    "    topk = sum(token_labels)\n",
    "    if topk < 1:\n",
    "        print(f\"Topk is less than 1 for {idx}th data\")\n",
    "        continue\n",
    "\n",
    "    output = c.predict([text]) # (num_text, num_class)\n",
    "    _, predicted = torch.max(torch.tensor(output), 1)\n",
    "    pred_label= predicted.detach().numpy()[0] #  Predicted top label index\n",
    "\n",
    "    #------------------------Below for LIME and LIPEx ------------------------#\n",
    "    explainer = LimeTextExplainer(class_names=label_names,random_state=42,bow=False, split_expression=split_expression)\n",
    "    # sample perturbation data, features2use: Union Set \n",
    "    sample_data, sample_labels, sample_distances, sample_weights, features2use = explainer.sample_data_and_features(text, c.predict, num_features=union_num, num_samples=num_samples)\n",
    "\n",
    "    # Compute LIPEx-List-s and LIME-List-s\n",
    "    # needed: yss, sorted_labels?, data, distances, used_features, weights\n",
    "    LIME_exp, LIPEx_exp = explainer.explain_instance_LIPEx_LIME(\n",
    "        sample_data,\n",
    "        sample_labels,\n",
    "        sample_distances,\n",
    "        sample_weights,\n",
    "        used_features=features2use,\n",
    "        new_top_labels=len(label_names),\n",
    "        true_label=[pred_label]\n",
    "    )\n",
    "\n",
    "    # LIME\n",
    "    LIME_topk_features_idx = [x[0] for x in LIME_exp.local_exp[pred_label]] # TopK features ranked descending\n",
    "    LIME_topk_words=[LIME_exp.domain_mapper.indexed_string.word(x) for x in LIME_topk_features_idx]\n",
    "    print('LIME_TopK_words:',LIME_topk_words)\n",
    "\n",
    "    # LIPEx explanation\n",
    "    local_pred = LIPEx_exp.local_pred.detach().cpu().numpy()\n",
    "    sorted_weights = [x[1] for x in sorted(zip(local_pred.tolist()[0], LIPEx_exp.local_exp.tolist()), key=lambda x: x[0], reverse=True)]\n",
    "\n",
    "    sorted_weights = np.array(sorted_weights)\n",
    "    sorted_row_indices = np.argsort(sorted_weights[0])[::-1]\n",
    "\n",
    "    LIPEx_used_features = [LIPEx_exp.used_features[idx] for idx in sorted_row_indices]\n",
    "    LIPEx_used_words = [LIPEx_exp.domain_mapper.indexed_string.word(x) for x in LIPEx_used_features]\n",
    "    print('LIPEx_TopK_words:',LIPEx_used_words)\n",
    "\n",
    "    LIPEx_topk_words = LIPEx_used_words[:topk]\n",
    "    LIPEx_recall = len(set(gold_tokens).intersection(set(LIPEx_topk_words)))/len(gold_tokens)\n",
    "    LIPEx_precision = len(set(gold_tokens).intersection(set(LIPEx_topk_words)))/len(LIPEx_topk_words)\n",
    "    LIPEx_f1 = 2*LIPEx_precision*LIPEx_recall/(LIPEx_precision+LIPEx_recall+1e-8)\n",
    "    LIPEx_recall_values.append(LIPEx_recall)\n",
    "    LIPEx_precision_values.append(LIPEx_precision)\n",
    "    LIPEx_f1_values.append(LIPEx_f1)\n",
    "\n",
    "    LIME_topk_words = LIME_topk_words[:topk]\n",
    "    LIME_recall = len(set(gold_tokens).intersection(set(LIME_topk_words)))/len(gold_tokens)\n",
    "    LIME_precision = len(set(gold_tokens).intersection(set(LIME_topk_words)))/len(LIME_topk_words)\n",
    "    LIME_f1 = 2*LIME_precision*LIME_recall/(LIME_precision+LIME_recall+1e-8)\n",
    "    LIME_recall_values.append(LIME_recall)\n",
    "    LIME_precision_values.append(LIME_precision)\n",
    "    LIME_f1_values.append(LIME_f1)\n",
    "\n",
    "\n",
    "print(f\"Average LIPEx Recall: {sum(LIPEx_recall_values)/len(LIPEx_recall_values)}, Average LIME Recall: {sum(LIME_recall_values)/len(LIME_recall_values)}\")\n",
    "print(f\"Average LIPEx Precision: {sum(LIPEx_precision_values)/len(LIPEx_precision_values)}, Average LIME Precision: {sum(LIME_precision_values)/len(LIME_precision_values)}\")\n",
    "print(f\"Average LIPEx F1: {sum(LIPEx_f1_values)/len(LIPEx_f1_values)}, Average LIME F1: {sum(LIME_f1_values)/len(LIME_f1_values)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hongbo_lipex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
