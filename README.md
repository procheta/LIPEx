# LIPEx
The fundamental approach to explaining machine learning models involves locally or globally approximating a model. Most current work in this field concentrates only on explaining the predicted class. However, gaining insight into the contributing factors for all potential classes at a particular test point, beyond just the predicted one, can offer valuable insights for machine learning and deep learning practitioners. This project proposes a perturbation-based multi-class explanation framework named **L**ocally **I**nterpretable **P**robabilistic **E**xplanation (LIPEx).

# Example
## Text
![Text demo ](Text.png)
## Image
![Image demo](Image.png)
